---
title: "M3_AG1_Países extremos en la implantación de Facebook"
author: "Lucía Menéndez y Milena Villanueva"
date: "2025-07-20"
output: html_document
---

```{r}

# Paquetes necesarios
required_packages <- c("tidyverse", "countrycode", "moments", "stargazer", "scales", "corrplot", "kableExtra", "writexl")

# Instalar los paquetes que aún no estén instalados
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) {
  install.packages(new_packages, quiet = TRUE)
}

# Cargar las librerías
library(tidyverse)
library(countrycode)
library(moments)
library(scales) 
library(stargazer) 
library(MASS)
library(corrplot)
library(knitr)
library(kableExtra)
library(writexl)


# URL del dataset
data_url <- "https://raw.githubusercontent.com/griu/mbdds_fc20/master/gestion_datos/www/fb_final.csv"

# Cargar el dataset con read_delim(), especificando separador y decimal
datos_facebook <- read_delim(
  data_url,
  delim = ";",
  locale = locale(decimal_mark = ","),
  col_types = cols(
    country_norm = col_character(),
    anyo = col_double(),
    facebook_num = col_double(),
    internet_por_num = col_double(),
    poblacion_num = col_double()
  )
)

print(head(datos_facebook))

```
## 1. Analiza mediante summary y boxplot, si hay (o no) países outliers respecto a la variable Facebook_por_Internet. Identifica cuáles son.

```{r}
# Crear variables necesarias
datos_facebook <- datos_facebook %>%
  mutate(
    facebook_por_num = facebook_num / poblacion_num * 100,
    facebook_por_internet = facebook_num / (poblacion_num * internet_por_num / 100) * 100
  )

# Análisis descriptivo
summary(datos_facebook$facebook_por_internet)

# Boxplot
boxplot(datos_facebook$facebook_por_internet,
        main = "Boxplot de Facebook_por_Internet",
        col = "skyblue",
        horizontal = TRUE,
        xlab = "% de usuarios de Internet que usan Facebook")

# Detectar outliers

# Cálculo de límites usando IQR
Q1 <- quantile(datos_facebook$facebook_por_internet, 0.25, na.rm = TRUE)
Q3 <- quantile(datos_facebook$facebook_por_internet, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1

lim_inf <- Q1 - 1.5 * IQR
lim_sup <- Q3 + 1.5 * IQR

# Filtrar países con valores extremos
outliers <- datos_facebook %>%
  filter(facebook_por_internet < lim_inf | facebook_por_internet > lim_sup) %>%
  dplyr::select(country_norm, anyo, facebook_por_internet) # <- CAMBIO AQUÍ: dplyr::select


# Mostrar tabla de resultados
knitr::kable(outliers, caption = "Países identificados como outliers en Facebook_por_Internet")


```
En el análisis de la variable **Facebook_por_Internet** se observan cuatro valores extremos al identificar como outliers aquellos datos que se alejan más de 1.5 veces el rango intercuartílico (IQR) del primer o tercer cuartil. Estos casos específicos corresponden a Bolivia (2023), Camboya (2023) y El Salvador (2023) e Indonesia (2010). 

En cuanto a la naturaleza de estos outliers sugiere una **inconsistencia** lógica en los datos, donde el porcentaje de usuarios de Facebook sobrepasa el 100% de los usuarios de Internet. Dado que el acceso a Internet es un prerrequisito para la utilización de Facebook, esta anomalía indica probablemente un error de medición, ya sea en las cifras de penetración de Internet o en el recuento de usuarios de Facebook para los países y años mencionados.


## 2. Ajusta, de nuevo, los modelos de la actividad 4 de facebook_por_num sobre internet_por_num separados por año. Dibuja el primer plot (es decir, plot(modelo,1)) del modelo de regresión de cada año. Analiza los residuos de cada modelo (2010 y 2023) e identifica los países outliers con un nivel de confianza del 95% en 2010 y en 2023. Comenta si son distintos a los outliers detectados en el punto anterior mediante boxplot.


```{r}
# Filtrar datos para 2010 y 2023, y crear rownames concatenando país y año
datos_2010 <- datos_facebook %>%
  filter(anyo == 2010) %>%
  filter(!is.na(facebook_por_num), !is.na(internet_por_num)) %>% 
  mutate(id = paste(country_norm, anyo, sep = "_")) %>%
  column_to_rownames("id")

datos_2023 <- datos_facebook %>%
  filter(anyo == 2023) %>%
  filter(!is.na(facebook_por_num), !is.na(internet_por_num)) %>% 
  mutate(id = paste(country_norm, anyo, sep = "_")) %>%
  column_to_rownames("id")

# Ajustar modelo lineal para 2010
modelo_2010 <- lm(facebook_por_num ~ internet_por_num, data = datos_2010) 

# Ajustar modelo lineal para 2023
modelo_2023 <- lm(facebook_por_num ~ internet_por_num, data = datos_2023) 

# Dibujar el primer plot (residuos vs valores ajustados) para cada modelo
par(mfrow = c(1, 2)) # Dos gráficos lado a lado

plot(modelo_2010, which = 1, main = "Residuos vs Ajustados (2010)")
plot(modelo_2023, which = 1, main = "Residuos vs Ajustados (2023)")

par(mfrow = c(1,1)) # Volver a 1 gráfico por defecto

# Identificar outliers mediante residuos studentizados (95% nivel confianza)
resid_2010 <- rstudent(modelo_2010)
resid_2023 <- rstudent(modelo_2023)

# Calcular el valor crítico de t para 95% de confianza
alpha <- 0.05
t_crit_2010 <- qt(1 - alpha/2, df = df.residual(modelo_2010))
t_crit_2023 <- qt(1 - alpha/2, df = df.residual(modelo_2023))

outliers_2010 <- names(resid_2010)[abs(resid_2010) > t_crit_2010] 
outliers_2023 <- names(resid_2023)[abs(resid_2023) > t_crit_2023] 

cat("\n--- Países outliers (residuos studentizados, 95% confianza) en 2010 ---\n")
print(outliers_2010)

cat("\n--- Países outliers (residuos studentizados, 95% confianza) en 2023 ---\n")
print(outliers_2023)

```

## 3. De forma cualitativa, comenta: ¿cuál puede ser la causa de la presencia de estos outliers en 2010? ¿Y en 2023?

```{r}

# Extraer solo los nombres de los países de los outliers de Q1 (IQR)
outliers_q1_countries <- unique(outliers_iqr$country_norm)

# Extraer solo los nombres de los países de los outliers de Q2 (Regresión)
outliers_q2_countries_2010 <- sub("_[0-9]{4}$", "", outliers_2010)
outliers_q2_countries_2023 <- sub("_[0-9]{4}$", "", outliers_2023)

# Combinar todos los nombres de países únicos
all_outlier_countries <- unique(c(outliers_q1_countries, outliers_q2_countries_2010, outliers_q2_countries_2023))

# Filtrar el dataset original para incluir solo estos países
datos_outliers <- datos_facebook %>%
  filter(country_norm %in% all_outlier_countries) %>%
  arrange(country_norm, anyo)

# Mostrar el dataset resultante
# knitr::kable(datos_outliers, caption = "Datos de los países identificados como Outliers")
print(datos_outliers) # Usamos print para verlo en consola si no estás en Rmd y haciendo knit
```

Se observan tres casuísticas distintas según el valor de la variable **facebook_por_internet.** Por un lado, los casos donde el porcentaje de usuarios de Facebook supera el de usuarios de Internet, lo que constituye una inconsistencia lógica y sugiere errores de medición. Ejemplos claros son Bolivia 2023 con 102.38% , Camboya 2023 con 125.28%, El Salvador 2023 con 110.03%, e Indonesia 2010 con 107.27%. 

Un segundo grupo está formado por países con una penetración de Facebook excepcionalmente alta respecto a los usuarios de Internet, rozando la saturación; Chile 2010 con un 98.94% es un ejemplo de esta alta adopción que lo desvía de la tendencia general. 

Finalmente, el tercer grupo lo conforman países con una penetración de Facebook notablemente baja entre sus usuarios de Internet, como Japón (1.57% en 2010 y 14.40% en 2023) y Corea del Sur (5.06% en 2010 y 19.66% en 2023); estos valores, aunque posibles, representan una desviación significativa de la norma en la relación analizada, indicando patrones de adopción atípicos o factores culturales diferenciadores.


## 4. A partir del plot 4 y 5 del modelo, comenta si los valores de Leverage y la D Cook indican la presencia de outliers. En cada caso comenta si estos valores indican que hay o no un impacto relevante sobre el ajuste de la regresión y porqué.

```{r}

# Filtrar datos para 2010 y 2023, gestionando NAs y creando rownames
datos_2010 <- datos_facebook %>%
  filter(anyo == 2010) %>%
  drop_na(facebook_por_num, internet_por_num) %>% 
  mutate(id = paste(country_norm, anyo, sep = "_")) %>%
  column_to_rownames("id") 

datos_2023 <- datos_facebook %>%
  filter(anyo == 2023) %>%
  drop_na(facebook_por_num, internet_por_num) %>% 
  mutate(id = paste(country_norm, anyo, sep = "_")) %>%
  column_to_rownames("id") 

# Ajustar modelos
modelo_2010 <- lm(facebook_por_num ~ internet_por_num, data = datos_2010) 
modelo_2023 <- lm(facebook_por_num ~ internet_por_num, data = datos_2023) 
# Plot 4 y 5 para 2010
par(mfrow = c(1,2))
plot(modelo_2010, which = 4, main = "2010 - Leverage vs Residuals")
plot(modelo_2010, which = 5, main = "2010 - Cook's Distance")

# Plot 4 y 5 para 2023
par(mfrow = c(1,2))
plot(modelo_2023, which = 4, main = "2023 - Leverage vs Residuals")
plot(modelo_2023, which = 5, main = "2023 - Cook's Distance")

par(mfrow = c(1,1)) 

# Valores numéricos de Leverage y Cook's Distance para análisis
leverage_2010 <- hatvalues(modelo_2010)
cooks_2010 <- cooks.distance(modelo_2010)

leverage_2023 <- hatvalues(modelo_2023)
cooks_2023 <- cooks.distance(modelo_2023)

# Combinar con nombres de países para identificar observaciones
datos_2010_outliers <- datos_2010 %>%
  mutate(leverage = leverage_2010,
         cooks_distance = cooks_2010) %>%
  filter(leverage > 2*mean(leverage) | cooks_distance > 4/(nrow(datos_2010) - length(coef(modelo_2010))))

datos_2023_outliers <- datos_2023 %>%
  mutate(leverage = leverage_2023,
         cooks_distance = cooks_2023) %>%
  filter(leverage > 2*mean(leverage) | cooks_distance > 4/(nrow(datos_2023) - length(coef(modelo_2023))))

# Mostrar posibles outliers con valores altos de leverage o Cook's Distance
print("Outliers 2010 (Leverage o Cook's D altos):")
print(datos_2010_outliers %>% dplyr::select(country_norm, internet_por_num, facebook_por_num, leverage, cooks_distance)) # CAMBIO: Usar dplyr::select

print("Outliers 2023 (Leverage o Cook's D altos):")
print(datos_2023_outliers %>% dplyr::select(country_norm, internet_por_num, facebook_por_num, leverage, cooks_distance)) # CAMBIO: Usar dplyr::select

```

En 2010, países como **Noruega** o **Países Bajos** presentan **valores de leverage altos**, ya que tienen valores de penetración de internet que los hacen extremos en el eje de los predictores.

En 2023, se observa mayor homogeneidad, pero países como **Afganistán** o **Uganda** destacan en leverage por sus valores extremos en la penetración de internet.

En 2010, los países con mayor Cook’s Distance fueron **Japón** y **Corea del Sur**, indicando que su eliminación alteraría significativamente el ajuste.

En 2023, **Bielorrusia** o **Camboya** también lideran en influencia.

Conclusión:
Sí existen países con alta influencia sobre el modelo, según Cook’s Distance.

Algunos países con residuos moderados pueden tener alta distancia de Cook si su leverage es alto (por ejemplo, valores extremos de internet).

No todos los outliers detectados por residuos coinciden con los de Cook/Leverage. Por tanto, ambos análisis son complementarios: los residuos nos indican si el país se ajusta mal, y Cook/Leverage si tiene un impacto fuerte en la recta.


## 5. Ajusta, ahora, los mismos modelos que en el punto 3, utilizando la versión robusta rlm de la librería MASS (algoritmo de los M-Estimadores). Presenta la comparación de los modelos lm y rlm mediante la función stargazer y en un gráfico de dispersión con las rectas de regresión (lm, rlm y loess). Comenta si observas cambios relevantes en el gráfico de las rectas de regresión, y en los coeficientes del modelo rlm respecto al modelo lm (algoritmo de mínimos cuadrados).

```{r}

# Modelos clásicos
modelo_lm_2010 <- lm(facebook_por_num ~ internet_por_num, data = datos_2010) 
modelo_lm_2023 <- lm(facebook_por_num ~ internet_por_num, data = datos_2023) 

# Modelos robustos con rlm (M-estimadores)
modelo_rlm_2010 <- rlm(facebook_por_num ~ internet_por_num, data = datos_2010) 
modelo_rlm_2023 <- rlm(facebook_por_num ~ internet_por_num, data = datos_2023) 

stargazer(modelo_lm_2010, modelo_rlm_2010,
          modelo_lm_2023, modelo_rlm_2023,
          type = "text",
          title = "Comparación modelos LM y RLM (2010 y 2023)",
          column.labels = c("LM 2010", "RLM 2010", "LM 2023", "RLM 2023"),
          digits = 3)

# Añadimos año como columna para facilitar uso en ggplot
datos_modelos <- datos_facebook %>%
  filter(anyo %in% c(2010, 2023)) %>%
  filter(!is.na(facebook_por_num), !is.na(internet_por_num)) 

ggplot(datos_modelos, aes(x = internet_por_num, y = facebook_por_num)) + 
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "blue", linetype = "dashed") +
  geom_smooth(method = "loess", se = FALSE, color = "green", linetype = "dotted") +
  geom_smooth(method = MASS::rlm, se = FALSE, color = "red", linetype = "solid") + 
  facet_wrap(~anyo, scales = "free") +
  labs(
    title = "Comparación de rectas de regresión (LM, RLM, LOESS)",
    subtitle = "Usuarios de Facebook por Internet (%) vs Usuarios de Internet (%) (2010 y 2023)", 
    x = "Usuarios de Internet (%)",
    y = "Usuarios de Facebook por Internet (%)"
  ) +
  theme_minimal()
```

Al comparar los modelos clásicos (lm) y robustos (rlm), se observa que los coeficientes pueden diferir ligeramente, especialmente en 2010. Esto indica que el modelo clásico fue más sensible a los outliers.
En el gráfico, la línea roja (modelo robusto) difiere de la azul (LM) principalmente en el tramo bajo de internet (países con menor conectividad), donde algunos valores atípicos afectan al ajuste.
La línea loess (verde) actúa como referencia no paramétrica: si se aleja mucho de la línea LM, es otra señal de que el modelo clásico está distorsionado por datos extremos.

Añado cosas:

Para ambos años, el modelo RLM muestra una pendiente consistentemente más pronunciada que el modelo LM. En 2010, la pendiente de RLM es 0.438, mientras que la de LM es 0.403. En 2023, la pendiente de RLM es 0.601, comparado con 0.544 de LM. Esto indica que la regresión robusta estima un mayor incremento en el porcentaje de usuarios de Facebook por cada punto porcentual de aumento en la penetración de Internet, al mitigar la influencia de los outliers.

La reducción del residual std. error confirma que los modelos robustos logran un mejor ajuste a la mayoría de los datos al minimizar la influencia de las observaciones atípicas.



## 6. Identifica la tipología de valores faltantes, según se comenta en la teoría y haz un análisis de correlaciones que permita identificar aquellas variables que tengan mayor poder explicativo de facebook_num para 2010. Para este análisis, puedes utilizar valores de 2023 para explicar los valores de 2010, ya que se trata de un proceso de imputación de valores faltantes previo a una modelización futura.

```{r}
# Identificar todas las filas en el dataset original 'datos_facebook' que contienen al menos un valor NA en cualquiera de sus columnas.
registros_con_na <- datos_facebook %>%
  filter(if_any(everything(), is.na))

# Mostrar los registros identificados
print("Registros de datos con valores faltantes:")
print(registros_con_na)

```

Explicar que faltan los datos de Facebook y cuál es la casuística.

```{r}

# --- 1. Preparar los datos para la matriz de correlaciones combinada ---
datos_para_pivot <- datos_facebook_extendido %>%
  filter(anyo %in% c(2010, 2023)) %>%
  dplyr::select(country_norm, anyo, facebook_num, internet_por_num, poblacion_num, internet_num, facebook_por_num, facebook_por_internet)

datos_correlacion_combinada_wide <- datos_para_pivot %>%
  pivot_wider(
    names_from = anyo,
    names_glue = "{.value}_{anyo}",
    values_from = c(facebook_num, internet_por_num, poblacion_num, internet_num, facebook_por_num, facebook_por_internet)
  ) %>%
  dplyr::select(-country_norm)

# --- 2. Calcular la matriz de correlaciones completa ---
matriz_correlacion_combinada <- cor(datos_correlacion_combinada_wide, use = "pairwise.complete.obs")

print("Matriz de Correlaciones Completa (2010 y 2023 combinados - como tabla con scroll):")

# Convertir la matriz a un data frame para kable y redondear los valores
matriz_correlacion_df <- as.data.frame(matriz_correlacion_combinada) %>%
  round(3) # Redondear a 3 decimales para mayor legibilidad

# Usar kable para crear una tabla que puede tener scroll horizontal
matriz_correlacion_df %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F) %>% # 'responsive' permite scroll
  scroll_box(width = "100%", height = "400px") # Ajusta el ancho y alto según sea necesario para el scroll

# Puedes comentar o eliminar el código del heatmap si prefieres solo la tabla.
# El código del heatmap anterior (con o sin los ajustes de cex) es una alternativa si decides volver a probarlo.

```

```{r}

# --- Exportar a Excel (.xlsx) para analizar mejor la matriz de correlaciones ---
writexl::write_xlsx(matriz_correlacion_df, "matriz_correlacion_combinada.xlsx")
print("Matriz de correlaciones exportada a 'matriz_correlacion_combinada.xlsx'")

```
Para imputar **facebook_num_2010**, las variables más predictivas son **internet_num_2010** (≈0.84), con una dependencia muy fuerte del acceso a internet en el mismo año. Seguidamente, **internet_num_2023** (≈0.75) y **facebook_num_2023** (≈0.75) también muestran una fuerte correlación positiva, indicando que el tamaño de la base de usuarios de internet y Facebook de un país mantiene una consistencia temporal. La **poblacion_num** en ambos años (2010 ≈0.63, 2023 ≈0.60) correlacionan con la respuesta, aunque en menor medida.

Destacar también la alta correlación entre algunas de estas variables explicativas. Por ejemplo, **internet_num_2010** y **poblacion_num_2010** correlacionan fuertemente (≈0.82), al igual que sus contrapartes de 2023 (≈0.83). Más aún, las variables de **internet_num** entre años (≈0.90) y, especialmente, las de **poblacion_num** entre años (≈0.999) muestran una correlación casi perfecta.

Esta multicolinealidad se deberá tener en cuenta en el proceso de imputación, ya que, aunque individualmente las variables puedan ser buenos predictores, la inclusión simultánea de variables altamente correlacionadas podría generar coeficientes inestables y dificultar la interpretación e individualización de los efectos independientes.


